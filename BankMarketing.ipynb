{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f0facb-46c7-42c8-b3ff-46339488c9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import scipy.stats as stats\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import statsmodels.api as sm\n",
    "from sklearn import tree\n",
    "from sklearn.inspection import PartialDependenceDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd516ac-0aa0-4038-a322-e5e073127517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "bank_df = pd.read_csv(r\"E:\\Michaelmas\\BU1745-Foundational BA\\Group Project\\bank-full.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2185fb9-28bb-471d-8826-1ef55234a941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null values in each column\n",
    "null_values = bank_df.isnull().sum()\n",
    "print(null_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8035eb9c-0e77-409b-bb23-dc5df9213e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f87d02-4358-455b-8aa9-33456583f47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c337dc18-460d-4990-8986-d0e0958adb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df['y']=bank_df['y'].map({'yes': 1, 'no': 0}).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef6de61-6453-479e-8f69-5ddfbbf3b86a",
   "metadata": {},
   "source": [
    "#### Ques 1: Key customer characteristics and campaign factors impacting the likelihood of term deposit subscription"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64743b00-ceb1-43e2-ae39-af0215714830",
   "metadata": {},
   "source": [
    "#### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632f4375-04b9-46a5-9f8c-6b905fc3b82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of Subscriptions by Month\n",
    "# Order of months\n",
    "month_order = [\"jan\", \"feb\", \"mar\", \"apr\", \"may\", \"jun\", \"jul\", \"aug\", \"sep\", \"oct\", \"nov\", \"dec\"]\n",
    "\n",
    "# Convert 'month' column to categorical type\n",
    "bank_df['month'] = pd.Categorical(bank_df['month'], categories=month_order, ordered=True)\n",
    "\n",
    "# Percentage of 'yes' and 'no' responses for each month\n",
    "subscription_counts = bank_df.groupby(['month', 'y']).size().unstack(fill_value=0)\n",
    "subscription_percentages = subscription_counts.div(subscription_counts.sum(axis=1), axis=0) * 100\n",
    "\n",
    "# Plot\n",
    "subscription_percentages.plot(kind='bar', stacked=False, color = ['#1f77b4', '#aec7e8'], figsize=(8, 7))\n",
    "# Adding labels and title\n",
    "plt.title('Percentage of Subscriptions (\"yes\" and \"no\") by Month')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Percentage of Subscriptions')\n",
    "plt.legend(title='Subscription Status', labels=['No', 'Yes'])\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a7db97-d22f-47dc-b4d3-5d2fa9dde393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binning the 'age' column \n",
    "bank_df['age_group'] = pd.cut(bank_df['age'], bins=[0, 25, 40, 60, 100], labels=['young', 'middle-aged', 'older', 'senior'])\n",
    "\n",
    "# Binning the 'balance' column\n",
    "bank_df['balance_group'] = pd.cut(bank_df['balance'], bins=[0, 1000, 10000, 100000], labels=['low', 'medium', 'high'])\n",
    "\n",
    "bank_df[['age', 'age_group', 'balance', 'balance_group']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbeaee5-96c4-4d17-98f7-7c972b7d1bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the relationship between 'age_group' and subscription (y)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(data=bank_df, x='age_group', hue='y', palette='Blues')\n",
    "plt.title('Term Deposit Subscription by Age Group')\n",
    "plt.xlabel('Age Group')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(title='Subscription', labels=['No Subscription (y=0)', 'Subscription (y=1)'])\n",
    "plt.show()\n",
    "\n",
    "# Visualizing the relationship between 'balance_group' and subscription (y)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(data=bank_df, x='balance_group', hue='y', palette='Blues')\n",
    "plt.title('Term Deposit Subscription by Balance Group')\n",
    "plt.xlabel('Balance Group')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(title='Subscription', labels=['No Subscription (y=0)', 'Subscription (y=1)'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea0f704-d714-4b59-a150-003c4ddaaf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of the 'balance' variable - to check if we need transformation while modeling\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.histplot(bank_df['balance'], bins=30, kde=True, color='skyblue')\n",
    "plt.xlabel(\"Balance\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Balance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99ab3ff-8ad2-4be1-8324-4d259d3ef513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of the 'duration' variable - to check if we need transformation while modeling (Data is rightly skewed)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.histplot(bank_df['duration'], bins=30, kde=True, color='skyblue')\n",
    "plt.xlabel(\"Call Duration (seconds)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Call Duration\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be6e143-8e50-47b1-8a11-ed71043600f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "subscribed_durations = bank_df[bank_df['y'] == 1]['duration']\n",
    "non_subscribed_durations = bank_df[bank_df['y'] == 0]['duration']\n",
    "\n",
    "# Calculate the count of subscriptions and non-subscriptions for each duration\n",
    "duration_counts_subscribed = subscribed_durations.value_counts().sort_index()\n",
    "duration_counts_non_subscribed = non_subscribed_durations.value_counts().sort_index()\n",
    "\n",
    "# Plotting both to see the distributions side-by-side\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(duration_counts_subscribed.index, duration_counts_subscribed.values, label='Subscribed (y=1)', color='blue')\n",
    "plt.plot(duration_counts_non_subscribed.index, duration_counts_non_subscribed.values, label='Not Subscribed (y=0)', color='skyblue')\n",
    "plt.xlabel(\"Call Duration (seconds)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Call Duration for Subscribed vs. Not Subscribed\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Can remove records where duration is more than 2000. Data loss is minimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a672b5-7beb-42e9-8438-6861c8ce9308",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df['job'].value_counts().sort_index()\n",
    "# Unknown jobs accounts for only 0.64% of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cfb508-8935-48f8-91d6-1f4feacba377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Term deposit subscription by job type\n",
    "bank_df['y_subscribed'] = bank_df['y'].map({1: 'Subscribed', 0: 'Not Subscribed'})\n",
    "job_subscription_counts = bank_df.groupby(['job', 'y_subscribed']).size().unstack(fill_value=0)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(14, 8))\n",
    "job_subscription_counts.plot(kind='bar', stacked=True, color=['#1f77b4', '#ff7f0e'], width=0.8)\n",
    "plt.xlabel(\"Job Type\")\n",
    "plt.ylabel(\"Number of People\")\n",
    "plt.title(\"Term Deposit Subscription Status by Job Type\")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.legend(title=\"Subscription Status\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade1abb6-45f4-4ec8-8782-d984e5fbd521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the unnnecessary columns\n",
    "bank_df = bank_df.drop(['age_group', 'balance_group', 'y_subscribed'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d142458-4470-456d-a00b-494c5c96e22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Occurrences of campaign\n",
    "campaign_counts = bank_df['campaign'].value_counts().sort_index()\n",
    "\n",
    "# Rate of term deposit subscriptions\n",
    "subscription_rate = bank_df['y'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"Number of campaigns contact counts for each campaign:-\")\n",
    "print(campaign_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e5cae7-241b-4a7b-8357-95950708658c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the distribution of 'campaign' by subscription status\n",
    "sns.histplot(data=bank_df, x='campaign', hue='y', bins=20, kde=True, palette='YlGnBu', edgecolor='black')\n",
    "plt.title('Distribution of Campaign Contacts by Subscription Status')\n",
    "plt.xlabel('Number of Contacts (campaign)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend(title='Subscription Status', labels=['No', 'Yes'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014d9566-50ce-4bcd-ba50-6a5f65b06c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Campaign values with counts >= 100\n",
    "valid_campaigns = campaign_counts[campaign_counts >= 100].index\n",
    "\n",
    "# Filter the DataFrame to include only rows where the campaign is in the valid_campaigns\n",
    "# and where the jobtype is  'unknown' \n",
    "filtered_bank_df = bank_df[(bank_df['campaign'].isin(valid_campaigns)) & (bank_df['job'] != 'unknown') & (bank_df['duration'] <= 2000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1b684d-f3ed-4b3e-8934-1c2f9ab4d066",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_bank_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe0d629-670d-4dc2-9840-4de93a5eeffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = filtered_bank_df.copy()\n",
    "data['subscription'] = data['y']\n",
    "\n",
    "# Bins for balance and duration\n",
    "balance_bins = [0, 2500, 3000, 5000, 10000] \n",
    "duration_bins = [0, 300, 400, 600, 900, 1200] \n",
    "\n",
    "balance_labels = ['<2500', '2500-3000', '3000-5000', '>5000']\n",
    "duration_labels = ['<300', '300-400', '400-600', '600-900', '>900']\n",
    "data['balance_bin'] = pd.cut(data['balance'], bins=balance_bins, labels=balance_labels)\n",
    "data['duration_bin'] = pd.cut(data['duration'], bins=duration_bins, labels=duration_labels)\n",
    "\n",
    "# Subscription rate\n",
    "subscription_rate = data.groupby(['balance_bin', 'duration_bin'])['subscription'].mean().unstack()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(subscription_rate, annot=True, fmt=\".2%\", cmap=\"YlGnBu\", cbar_kws={'label': 'Subscription Rate (%)'})\n",
    "plt.xlabel(\"Call Duration (seconds)\")\n",
    "plt.ylabel(\"Balance (€)\")\n",
    "plt.title(\"Subscription Rate by Balance and Call Duration\")\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1b162b-b325-4c28-b946-641b99221438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummies for categorical variables\n",
    "bank_dummies_df = pd.get_dummies(filtered_bank_df, drop_first = True, dtype = int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555b9022-1149-4037-8eb8-87c091751f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix of the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5aa952-934a-46ea-ba6f-f61845446a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = bank_dummies_df.drop(['y'], axis=1).corr()\n",
    "\n",
    "plt.figure(figsize=(26, 20))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", vmin=-1, vmax=1)\n",
    "plt.title(\"Correlation Matrix of Variables\")\n",
    "plt.show()\n",
    "\n",
    "# Highly correlated feature pairs\n",
    "threshold = 0.8\n",
    "high_corr_pairs = []\n",
    "for col1 in corr_matrix.columns:\n",
    "    for col2 in corr_matrix.columns:\n",
    "        if col1 != col2 and abs(corr_matrix.loc[col1, col2]) > threshold:\n",
    "            pair = tuple(sorted([col1, col2]))  # Sort to avoid duplicate pairs\n",
    "            if pair not in high_corr_pairs:\n",
    "                high_corr_pairs.append(pair + (corr_matrix.loc[col1, col2],))\n",
    "\n",
    "print(\"Highly Correlated Feature Pairs (Correlation > 0.8):\")\n",
    "for pair in high_corr_pairs:\n",
    "    print(f\"{pair[0]} - {pair[1]}: Correlation = {pair[2]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3572359-ca24-44f0-a440-7e70e0fecebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for multi-colinearity via Variance Inflation Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e21d710-a1bb-4fcc-ae50-6d36a26c00bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = bank_dummies_df.drop(columns='y') \n",
    "\n",
    "# VIF for each feature\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X.columns\n",
    "vif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "print(vif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccfba23-2d01-449d-8bd8-ac82ce16f612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1654229a-c1d5-4581-8dad-39d58d1c471f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segregating independent and target variables\n",
    "x = bank_dummies_df.drop(columns='y')  \n",
    "y = bank_dummies_df['y'] \n",
    "\n",
    "# Fit the Decision Tree Classifier\n",
    "clf = DecisionTreeClassifier(random_state=19)\n",
    "clf.fit(x, y)\n",
    "\n",
    "feature_importances = pd.DataFrame({\n",
    "    'feature': x.columns,\n",
    "    'importance': clf.feature_importances_\n",
    "}).sort_values(by='importance', ascending=False)\n",
    "\n",
    "print(feature_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a079b44-2ba4-4e2b-9257-5d162763f924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the feature importances\n",
    "plt.figure(figsize=(14, 11))\n",
    "plt.barh(feature_importances['feature'], feature_importances['importance'], color='royalblue')\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Feature Importance from Decision Tree Classifier')\n",
    "plt.gca().invert_yaxis() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5271ea23-67e9-41c6-b6d3-e8a1893666cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting relevant columns for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a731a83e-e135-4755-b27f-b540a8d71d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing poutcome_unknown as its VIF is high and is also highly co-related to pdays. Also, pdays has more feature importance compared to poutcome_unknown\n",
    "# Removing education, marital, loan_yes, default_yes and their encoded variables as their feature importance is less than 0.01\n",
    "bank_final_df = bank_dummies_df[\n",
    "                                 [\n",
    "                                      'age', 'balance', 'duration', 'campaign', 'pdays', 'day','previous',\n",
    "                                      'job_blue-collar', 'job_entrepreneur', 'job_housemaid',\n",
    "                                      'job_management', 'job_retired', 'job_self-employed', 'job_services',\n",
    "                                      'job_student', 'job_technician', 'job_unemployed', 'housing_yes', \n",
    "                                      'contact_telephone', 'contact_unknown', 'month_feb',\n",
    "                                      'month_mar', 'month_apr', 'month_may', 'month_jun', 'month_jul',\n",
    "                                      'month_aug', 'month_sep', 'month_oct', 'month_nov', 'month_dec',\n",
    "                                      'poutcome_other', 'poutcome_success', 'y'\n",
    "                                 ]\n",
    "                               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f4f2fd-d5fc-459a-b263-8bdeb74faef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_final_df['y'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f687cf6-d837-48fd-8ac6-2b5526bf8064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balancing the data by duplicating records as number of 1's(11.84%) are very less compared to 0's(88.16%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb6cd6d-c789-4c4a-a154-87119a0e1ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the data into majority and minority classes\n",
    "data_majority = bank_final_df[bank_final_df['y'] == 0]  # Adjust if 0 is the majority class\n",
    "data_minority = bank_final_df[bank_final_df['y'] == 1]  # Adjust if 1 is the minority class\n",
    "\n",
    "# Calculating duplication factor\n",
    "duplication_factor = len(data_majority) // len(data_minority)\n",
    "\n",
    "# Duplicate the minority class\n",
    "data_minority_duplicated = pd.concat([data_minority] * duplication_factor, ignore_index=True)\n",
    "\n",
    "# Combining the majority class and duplicated minority class\n",
    "balanced_df = pd.concat([data_majority, data_minority_duplicated], ignore_index=True)\n",
    "\n",
    "balanced_data_majority = balanced_df[balanced_df['y'] == 0]\n",
    "balanced_data_minority = balanced_df[balanced_df['y'] == 1]\n",
    "\n",
    "print(\"Number of majority class instances after balancing:\", len(balanced_data_majority))\n",
    "print(\"Number of minority class instances after balancing:\", len(balanced_data_minority))\n",
    "print(\"Balanced dataset shape:\", balanced_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f549cc68-9cf8-4d8b-9650-c3075eac9923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target and predictors variable(s)\n",
    "X = balanced_df[\n",
    "                    [\n",
    "                          'age', 'balance', 'duration', 'campaign', 'pdays', 'day','previous',\n",
    "                          'job_blue-collar', 'job_entrepreneur', 'job_housemaid',\n",
    "                          'job_management', 'job_retired', 'job_self-employed', 'job_services',\n",
    "                          'job_student', 'job_technician', 'job_unemployed', \n",
    "                          'housing_yes', 'contact_telephone', 'contact_unknown', 'month_feb',\n",
    "                          'month_mar', 'month_apr', 'month_may', 'month_jun', 'month_jul',\n",
    "                          'month_aug', 'month_sep', 'month_oct', 'month_nov', 'month_dec',\n",
    "                          'poutcome_other', 'poutcome_success'\n",
    "                    ]\n",
    "               ]\n",
    "\n",
    "y = balanced_df['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c362420-7382-4245-b9a4-2dee0e55431c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5f8e3a-4a2b-4884-a687-38565d306318",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define and scale numerical features for Logistic Regression\n",
    "numerical_features = ['age', 'balance', 'duration', 'campaign', 'pdays', 'day', 'previous']\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Duration data is rightly skewed\n",
    "X['duration'] = np.log1p(X['duration'])  # log1p handles zero values by computing log(1 + x)\n",
    "X_scaled = X.copy()\n",
    "X_scaled[numerical_features] = scaler.fit_transform(X_scaled[numerical_features])\n",
    "\n",
    "# Train-Test Split - 80% train and 20% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=19, stratify=y)\n",
    "\n",
    "# Initialize and train Logistic Regression model\n",
    "logreg = LogisticRegression(max_iter=1000, random_state=19, class_weight='balanced')\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = logreg.predict(X_test)\n",
    "y_pred_proba = logreg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"\\nClassification Report:\\n\", class_report)\n",
    "print(\"\\nROC- Area under curve:\\n\", roc_auc)\n",
    "\n",
    "# Confusion Matrix Plot\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "            xticklabels=['No', 'Yes'], yticklabels=['No', 'Yes'])\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# ROC Curve Plot\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f\"ROC Curve (AUC = {roc_auc:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], 'k--')  # Diagonal line for random guessing\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Coefficients\n",
    "coefficients = logreg.coef_[0]\n",
    "feature_names = X_scaled.columns\n",
    "\n",
    "# Odds and Probability calculation\n",
    "odds = np.exp(coefficients)  # Odds ratio\n",
    "probability = odds / (1 + odds)  # Probability from odds\n",
    "\n",
    "# DataFrame of features, coefficients, odds, and probability\n",
    "feature_summary = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Coefficient': coefficients,\n",
    "    'Odds': odds,\n",
    "    'Probability': probability\n",
    "})\n",
    "\n",
    "# Logit Equation\n",
    "intercept = logreg.intercept_[0]\n",
    "print(f\"\\nLogit Equation: log(odds) = {intercept:.4f} + \" + \" + \".join([f\"{coef:.4f}*{name}\" for coef, name in zip(coefficients, feature_names)]))\n",
    "\n",
    "# Feature Summary\n",
    "print(\"\\nFeature Summary with Coefficient, Odds, and Probability:\")\n",
    "print(feature_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6576a318-76ec-450e-b59e-3447a54e8994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be27cd1-43a8-4b0f-8024-8aacdc8976af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add an intercept column to X_train for statsmodels (sklearn adds it automatically, but statsmodels does not)\n",
    "X_train_sm = sm.add_constant(X_train)  # Adds a constant term to the predictors\n",
    "\n",
    "# Fit logistic regression model using statsmodels\n",
    "logit_model = sm.Logit(y_train, X_train_sm)\n",
    "result = logit_model.fit()\n",
    "\n",
    "print(result.summary())\n",
    "\n",
    "# Extracting coefficients, p-values, and other statistics into a DataFrame\n",
    "summary_df = pd.DataFrame({\n",
    "    \"Feature\": X_train_sm.columns,\n",
    "    \"Coefficient\": result.params.values,\n",
    "    \"P-value\": result.pvalues.values\n",
    "})\n",
    "\n",
    "print(summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41e316b-b799-4f69-8261-bf9261b529f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter significant features based on their p-value\n",
    "significant_features = summary_df[summary_df['P-value'] < 0.05].sort_values(by=\"Coefficient\", key=abs, ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(significant_features['Feature'], significant_features['Coefficient'], color=np.where(significant_features['Coefficient'] > 0, 'royalblue', 'skyblue'))\n",
    "plt.xlabel(\"Coefficient Value\")\n",
    "plt.title(\"Significant Features Affecting Term Deposit Subscription Likelihood (p < 0.05)\")\n",
    "plt.gca().invert_yaxis()  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec7c0c4-3371-4045-9d6b-571411b0ddb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0755d71-3932-4882-986c-6ff2cdd890e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the depth of the tree for model tuning and performance\n",
    "max_depth = 10  \n",
    "\n",
    "# Initialize and train the Decision Tree Classifier\n",
    "dt_clf = DecisionTreeClassifier(random_state=19, max_depth=max_depth, class_weight='balanced')\n",
    "dt_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = dt_clf.predict(X_test)\n",
    "y_pred_proba = dt_clf.predict_proba(X_test)[:, 1]  \n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# Results\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"\\nClassification Report:\\n\", class_report)\n",
    "print(\"\\nROC- Area under curve:\\n\", roc_auc)\n",
    "\n",
    "# Confusion Matrix Plot\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "            xticklabels=['No', 'Yes'], yticklabels=['No', 'Yes'])\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# ROC Curve Plot\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f\"ROC Curve (AUC = {roc_auc:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], 'k--') \n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Save predictions to CSV because the accuracy of Decision Tree is more \n",
    "predictions_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred,\n",
    "    'Predicted_Probability': y_pred_proba\n",
    "})\n",
    "\n",
    "predictions_df.to_csv('term_deposit_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2932441-b8ff-4cd4-ace8-a403276ab368",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = dt_clf.feature_importances_\n",
    "\n",
    "# DataFrame of features and their scores\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(feature_importance_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90c2c9f-d016-4a8b-b855-d1ee331e2539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Partial Dependence for the top features\n",
    "PartialDependenceDisplay.from_estimator(dt_clf, X_train, features=[2, 32, 19])  \n",
    "plt.suptitle(\"Partial Dependence of Key Features on Subscription Likelihood\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f9eaaa-cd7f-498e-97ed-87229323f957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC for Logistic Regression\n",
    "fpr_logreg, tpr_logreg, _ = roc_curve(y_test, logreg.predict_proba(X_test)[:, 1])\n",
    "roc_auc_logreg = roc_auc_score(y_test, logreg.predict_proba(X_test)[:, 1])\n",
    "\n",
    "# ROC for Decision Tree\n",
    "fpr_dt, tpr_dt, _ = roc_curve(y_test, dt_clf.predict_proba(X_test)[:, 1])\n",
    "roc_auc_dt = roc_auc_score(y_test, dt_clf.predict_proba(X_test)[:, 1])\n",
    "\n",
    "# Plotting both ROC curves\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr_logreg, tpr_logreg, label=f\"Logistic Regression (AUC = {roc_auc_logreg:.2f})\", color=\"blue\")\n",
    "plt.plot(fpr_dt, tpr_dt, label=f\"Decision Tree (AUC = {roc_auc_dt:.2f})\", color=\"green\")\n",
    "plt.plot([0, 1], [0, 1], 'k--')  # Diagonal line for random guessing\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve Comparison: Logistic Regression vs Decision Tree\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02270ad9-9a48-4fb9-ad5d-431091967e1c",
   "metadata": {},
   "source": [
    "#### Ques 2: Seasonal trends in call duration, monthly patterns, and subscription counts for predicting the likelihood of a customer subscribing to a term deposit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5047ae-06c3-4866-b2ad-c1fc4243e8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_q2_df = bank_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5217e98a-f047-47e6-b6f5-28efae2b71ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_data = bank_q2_df.groupby('month').agg(\n",
    "                                                avg_duration=('duration', 'mean'),\n",
    "                                                subscriber_count=('y', 'sum')\n",
    "                                              ).reset_index()\n",
    "monthly_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22eaa0de-465a-48de-b3e7-b1833827764b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Analysis & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5ce916-7001-4972-ab0f-eaa251158a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordering month as a categorical variable\n",
    "bank_q2_df['month'] = pd.Categorical(\n",
    "                                        bank_q2_df['month'],\n",
    "                                        categories=['jan', 'feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec'],\n",
    "                                        ordered=True\n",
    "                                    )\n",
    "\n",
    "# Calculating monthly average duration and subscriber counts\n",
    "monthly_data = bank_q2_df.groupby('month').agg(\n",
    "                                                avg_duration=('duration', 'mean'),\n",
    "                                                subscriber_count=('y', 'sum')\n",
    "                                              ).reset_index()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Monthly average duration (line plot for trend)\n",
    "sns.lineplot(data=monthly_data, x='month', y='avg_duration', marker='o', color='blue', label=\"Average Call Duration(seconds)\")\n",
    "\n",
    "# Monthly subscriber count (bar plot)\n",
    "sns.barplot(data=monthly_data, x='month', y='subscriber_count', color='royalblue', alpha=0.8, label=\"Subscriber Count\")\n",
    "\n",
    "# Background shading for seasonal periods\n",
    "plt.axvspan(4, 7, color='peachpuff', alpha=0.3, label=\"Summer Months (May-Aug)\")\n",
    "plt.axvspan(9, 11, color='lightblue', alpha=0.3, label=\"Holiday Season (Oct-Dec)\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Values\")\n",
    "plt.title(\"Seasonal Trends: Average Call Duration and Subscriber Count by Month\")\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8b6330-adb0-479a-bb9b-34f1ab60c8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dummies for categorical variables\n",
    "bank_q2_dummies_df = pd.get_dummies(bank_q2_df, columns=['month'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa67947f-18d4-4d24-a837-da0509f22be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73936265-ea37-4ecb-8900-520763849a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seasonal indicators for summer and holiday seasons\n",
    "bank_q2_dummies_df['is_summer'] = bank_q2_dummies_df[['month_may', 'month_jun', 'month_jul', 'month_aug']].sum(axis=1).astype(bool).astype(int)\n",
    "bank_q2_dummies_df['is_holiday_season'] = bank_q2_dummies_df[['month_oct', 'month_nov', 'month_dec']].sum(axis=1).astype(bool).astype(int)\n",
    "\n",
    "# Define features and target\n",
    "features = ['duration', 'is_summer', 'is_holiday_season'] + [col for col in bank_q2_dummies_df.columns if col.startswith('month_')]\n",
    "X = bank_q2_dummies_df[features]\n",
    "y = bank_q2_dummies_df['y'] \n",
    "\n",
    "corr_matrix = X.corr()\n",
    "\n",
    "# Correlation matrix plot\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", vmin=-1, vmax=1)\n",
    "plt.title(\"Correlation Matrix of Independent Variables\")\n",
    "plt.show()\n",
    "\n",
    "# Identifying highly correlated pairs\n",
    "threshold = 0.8\n",
    "high_corr_pairs = [(col1, col2, corr_matrix.loc[col1, col2]) \n",
    "                   for col1 in corr_matrix.columns \n",
    "                   for col2 in corr_matrix.columns \n",
    "                   if col1 != col2 and abs(corr_matrix.loc[col1, col2]) > threshold]\n",
    "\n",
    "print(\"Highly Correlated Feature Pairs (Correlation > 0.8):\")\n",
    "for pair in high_corr_pairs:\n",
    "    print(f\"{pair[0]} - {pair[1]}: Correlation = {pair[2]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bbc90f-b69a-4303-ace5-9f586982d464",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_q2_final_df = bank_q2_dummies_df[\n",
    "                                        [\n",
    "                                           'duration', 'is_summer', 'is_holiday_season', 'month_feb', 'month_mar',\n",
    "                                           'month_apr', 'month_may', 'month_jun', 'month_jul', 'month_aug',\n",
    "                                           'month_sep', 'month_oct', 'month_nov', 'month_dec', 'y'\n",
    "                                        ]\n",
    "                                    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5238a484-5468-477b-b20c-0a48b7e512da",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_q2_final_df['y'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d002dc2-d3c1-40f9-a039-8102ad0612a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balancing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62b4d70-5052-4f47-a499-8fbdecee07a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the data into majority and minority classes\n",
    "data_majority = bank_q2_final_df[bank_q2_final_df['y'] == 0]  # Adjust if 0 is the majority class\n",
    "data_minority = bank_q2_final_df[bank_q2_final_df['y'] == 1]  # Adjust if 1 is the minority class\n",
    "\n",
    "# Calculating duplication factor\n",
    "duplication_factor = len(data_majority) // len(data_minority)\n",
    "\n",
    "# Duplicate the minority class\n",
    "data_minority_duplicated = pd.concat([data_minority] * duplication_factor, ignore_index=True)\n",
    "\n",
    "# Combining the majority class and duplicated minority class\n",
    "balanced_q2_df = pd.concat([data_majority, data_minority_duplicated], ignore_index=True)\n",
    "\n",
    "balanced_data_majority = balanced_q2_df[balanced_q2_df['y'] == 0]\n",
    "balanced_data_minority = balanced_q2_df[balanced_q2_df['y'] == 1]\n",
    "\n",
    "print(\"Number of majority class instances after balancing:\", len(balanced_data_majority))\n",
    "print(\"Number of minority class instances after balancing:\", len(balanced_data_minority))\n",
    "print(\"Balanced dataset shape:\", balanced_q2_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170d4149-812b-48d3-afbe-b6022cdf055a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the independent and dependent variables for modeling\n",
    "X = balanced_q2_df[features]\n",
    "y = balanced_q2_df['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c1b356-8a26-4522-96b9-38522d4a31ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log transform the 'duration' feature\n",
    "X['duration'] = np.log1p(X['duration'])  # log1p applies log(1 + x) to handle zero values\n",
    "\n",
    "# Scaling numerical features\n",
    "scaler = StandardScaler()\n",
    "X[['duration']] = scaler.fit_transform(X[['duration']])  # Scaling only 'log_duration'\n",
    "\n",
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=19, stratify=y)\n",
    "\n",
    "# Initialize and train Logistic Regression model\n",
    "logreg = LogisticRegression(max_iter=1000, random_state=19, class_weight='balanced')\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = logreg.predict(X_test)\n",
    "y_pred_proba = logreg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"ROC-AUC Score:\", roc_auc)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# ROC-AUC metrics\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color=\"green\", label=f\"ROC Curve (AUC = {roc_auc:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], 'k--') \n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Coefficients from the logistic regression model\n",
    "intercept = logreg.intercept_[0]  \n",
    "coefficients = logreg.coef_[0]    \n",
    "feature_names = X.columns \n",
    "\n",
    "# DataFrame to display the coefficients, odds, and probabilities\n",
    "coef_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Coefficient': coefficients,\n",
    "    'Odds': np.exp(coefficients),  # Odds = exp(Coefficient)\n",
    "    'Probability': np.exp(coefficients) / (1 + np.exp(coefficients))  # Probability from odds\n",
    "})\n",
    "\n",
    "# Coefficients\n",
    "coef_df = coef_df.reindex(coef_df['Coefficient'].abs().sort_values(ascending=False).index)\n",
    "print(\"\\nSorted Coefficients (by absolute value):\")\n",
    "print(coef_df)\n",
    "\n",
    "# logit equation\n",
    "logit_equation = f\"log(odds) = {intercept:.4f} + \" + \" + \".join([f\"{coef:.4f}*{name}\" for coef, name in zip(coefficients, feature_names)])\n",
    "print(\"\\nLogit Equation:\")\n",
    "print(logit_equation)\n",
    "\n",
    "# DataFrame to save actual values, predicted values, and predicted probabilities\n",
    "predictions_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred,\n",
    "    'Predicted_Probability': y_pred_proba\n",
    "})\n",
    "\n",
    "# Save to CSV file\n",
    "predictions_df.to_csv('term_deposit_predictions_by_seasonality.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847416cf-5eb3-40b3-91c6-379c813fa079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmenting customers based on likelihood of subscribing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b7eb7f-cc43-4986-a53e-4af982b4c3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['predicted_probability'] = logreg.predict_proba(X)[:, 1] \n",
    "\n",
    "# Segments based on probability thresholds\n",
    "X['subscription_likelihood'] = pd.cut(X['predicted_probability'], bins=[0, 0.5, 0.75, 1], \n",
    "                                      labels=['Less Likely', 'Moderately Likely', 'Highly Likely'])\n",
    "\n",
    "print(X['subscription_likelihood'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82184cae-4acc-4a5f-9511-2c8cd4ccce7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Season column based on the 'is_summer' and 'is_holiday_season' \n",
    "X['season'] = np.select(\n",
    "    [\n",
    "        X['is_summer'] == 1,\n",
    "        X['is_holiday_season'] == 1\n",
    "    ],\n",
    "    [\n",
    "        'Summer',\n",
    "        'Holiday Season'\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Aggregate data to count the number of customers in each likelihood segment per season\n",
    "seasonal_likelihood_counts = X.groupby(['season', 'subscription_likelihood']).size().reset_index(name='customer_count')\n",
    "\n",
    "seasonal_order = ['Summer', 'Holiday Season']\n",
    "seasonal_likelihood_counts['season'] = pd.Categorical(seasonal_likelihood_counts['season'], categories=seasonal_order, ordered=True)\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(7, 4))\n",
    "sns.barplot(data=seasonal_likelihood_counts, x='season', y='customer_count', hue='subscription_likelihood', palette=\"Blues\", width = 0.3)\n",
    "plt.title(\"Customer Subscription Likelihood Segments by Season\")\n",
    "plt.xlabel(\"Season\")\n",
    "plt.ylabel(\"Customer Count\")\n",
    "plt.legend(title=\"Likelihood Segment\", loc='upper right')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c75172fd-250e-4987-8f6a-9c5c5d35466b",
   "metadata": {},
   "source": [
    "#### Ques 3 Financial and demographic characteristics of clients who are likely to have a housing loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6966c6-da82-459e-899c-f6f0907e26d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_q3_df = bank_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6d090f-323e-492a-aaa2-2d09284d9c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_q3_df = bank_q3_df[['balance', 'loan', 'default', 'y', 'marital', 'age', 'housing']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d17b4c-4fe5-409a-b6e7-2fa8a852d76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of `housing`\n",
    "plt.figure(figsize=(5, 3))\n",
    "sns.countplot(data=bank_df, x='housing', width=0.3)\n",
    "plt.title(\"Distribution of Housing Loan\")\n",
    "plt.xlabel(\"Housing Loan\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d98962-bea9-435b-819d-316661a8c3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Housing loan by age\n",
    "plt.figure(figsize=(9, 3))\n",
    "sns.histplot(data=bank_q3_df, x='age', hue='housing', multiple='stack', bins=20)\n",
    "plt.title(\"Distribution of Housing Loan by Age\")\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f470950-2b82-4f55-84cf-2344e1466035",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 2))\n",
    "sns.countplot(data=bank_q3_df, x='marital', hue='housing',  width =0.3)\n",
    "plt.title(\"Housing Loan by Marital Status\")\n",
    "plt.xlabel(\"Marital Status\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bbce33-c79e-4926-9fcc-45f52fc07a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of 'housing' loan status by 'loan' status\n",
    "loan_housing_counts = bank_q3_df.groupby(['housing', 'loan']).size().unstack(fill_value=0)\n",
    "\n",
    "# Convert counts to percentages\n",
    "loan_housing_percentages = loan_housing_counts.div(loan_housing_counts.sum(axis=1), axis=0) * 100\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(7, 4))\n",
    "loan_housing_percentages.plot(kind='bar', stacked=True, width=0.3, ax=ax)  \n",
    "\n",
    "plt.title(\"Percentage Distribution of Personal Loan Status with Housing Loan\")\n",
    "plt.xlabel(\"Housing Loan\")\n",
    "plt.ylabel(\"Percentage\")\n",
    "plt.legend(title=\"Personal Loan Status\", labels=['No Personal Loan', 'Personal Loan'])\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f05a952-20f1-4e78-9e6e-b1e69533a0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting housing to binary\n",
    "bank_q3_df['housing'] = bank_q3_df['housing'].map({'yes': 1, 'no': 0}).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5f21bf-8fca-4908-80f8-05888b686111",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'y' in bank_q3_df.columns:\n",
    "    bank_q3_df = bank_q3_df.rename(columns={'y': 'term_deposit'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abaf53f7-f0ad-4d45-a561-f8279330d7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_q3_dummies = pd.get_dummies(bank_q3_df, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094d325d-aedb-4f93-8338-375fcaaec139",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_q3_dummies.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ba06ae-9a45-43a0-a3c6-b241dce10570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Matrix of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b467cf-8505-43ce-970c-0734aee86d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = bank_q3_dummies.drop(columns = 'housing').corr()\n",
    "\n",
    "# Plot the Correlation Matrix\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, fmt=\".2f\", linewidths=0.5)\n",
    "plt.title(\"Correlation Matrix for Features\")\n",
    "plt.show()\n",
    "\n",
    "# Identifying highly correlated pairs\n",
    "threshold = 0.8\n",
    "high_corr_pairs = [(col1, col2, correlation_matrix.loc[col1, col2]) \n",
    "                   for col1 in correlation_matrix.columns \n",
    "                   for col2 in correlation_matrix.columns \n",
    "                   if col1 != col2 and abs(correlation_matrix.loc[col1, col2]) > threshold]\n",
    "\n",
    "print(\"Highly Correlated Feature Pairs (Correlation > 0.8):\")\n",
    "for pair in high_corr_pairs:\n",
    "    print(f\"{pair[0]} - {pair[1]}: Correlation = {pair[2]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46e8ebc-dbf0-4eac-adde-c928077eb430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dependent variable and predictors\n",
    "X = bank_q3_dummies.drop(columns='housing')\n",
    "y = bank_q3_dummies['housing']\n",
    "\n",
    "#  Fit the Decision Tree Classifier \n",
    "tree_model = DecisionTreeClassifier(random_state=19)\n",
    "tree_model.fit(X, y)\n",
    "\n",
    "# Extract and Plot Feature Importance\n",
    "feature_importances = pd.Series(tree_model.feature_importances_, index=X.columns)\n",
    "feature_importances = feature_importances.sort_values(ascending=False)\n",
    "feature_importance_df = feature_importances.reset_index()\n",
    "feature_importance_df.columns = ['Feature', 'Importance']\n",
    "print(\"Feature Importances for Predicting Housing Loan:\")\n",
    "print(feature_importance_df)\n",
    "\n",
    "# Plot the feature importances\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.barplot(x=feature_importances, y=feature_importances.index, palette=\"Blues\")\n",
    "plt.title(\"Feature Importance for Predicting Housing Loan Ownership\")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513de438-ff58-4520-9245-72ea33dc77a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_q3_df['housing'].value_counts().sort_index() # More or less balanced data - No need to do balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843488a2-dabc-4829-a67d-88ffff15d3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e982ad66-b747-4882-aba2-9695c4a95441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the features and target\n",
    "X = bank_q3_dummies.drop(columns='housing')\n",
    "y = bank_q3_dummies['housing']\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=19, stratify=y)\n",
    "\n",
    "# Scale the numerical variables\n",
    "scaler = StandardScaler()\n",
    "X_train[['balance', 'age']] = scaler.fit_transform(X_train[['balance', 'age']])\n",
    "X_test[['balance', 'age']] = scaler.transform(X_test[['balance', 'age']])\n",
    "\n",
    "# Initialize and train the logistic regression model\n",
    "logreg = LogisticRegression(max_iter=1000, random_state=19, class_weight='balanced')\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = logreg.predict(X_test)\n",
    "y_pred_proba = logreg.predict_proba(X_test)[:, 1]  # Probabilities for ROC-AUC calculation\n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"ROC-AUC Score:\", roc_auc)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "            xticklabels=[0, 1], yticklabels=[0, 1])\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Coefficients from the logistic regression model\n",
    "intercept = logreg.intercept_[0]\n",
    "coefficients = logreg.coef_[0]\n",
    "feature_names = X.columns\n",
    "\n",
    "# DataFrame with feature details, including odds and probability\n",
    "coef_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Coefficient': coefficients,\n",
    "    'Odds': np.exp(coefficients),  # Odds = exp(Coefficient)\n",
    "    'Probability': np.exp(coefficients) / (1 + np.exp(coefficients))  # Probability from odds\n",
    "})\n",
    "\n",
    "# Coefficients\n",
    "coef_df = coef_df.reindex(coef_df.Coefficient.abs().sort_values(ascending=False).index)\n",
    "print(\"\\nSorted Coefficients:\")\n",
    "print(coef_df)\n",
    "\n",
    "# Logit equation\n",
    "logit_equation = f\"log(odds) = {intercept:.4f} \" + \" + \".join([f\"{coef:.4f}*{name}\" for coef, name in zip(coefficients, feature_names)])\n",
    "print(\"\\nLogit Equation:\")\n",
    "print(logit_equation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c5c35a-63ec-4ea5-9057-1117935b6996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictors and target\n",
    "X = bank_q3_dummies.drop(columns='housing')\n",
    "y = bank_q3_dummies['housing']\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=19, stratify=y)\n",
    "\n",
    "# Scaling numerical variables\n",
    "scaler = StandardScaler()\n",
    "X_train[['balance', 'age']] = scaler.fit_transform(X_train[['balance', 'age']])\n",
    "X_test[['balance', 'age']] = scaler.transform(X_test[['balance', 'age']])\n",
    "\n",
    "# Initialize and train the Decision Tree model\n",
    "dt_clf = DecisionTreeClassifier(max_depth=3, random_state=19, class_weight='balanced')\n",
    "dt_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = dt_clf.predict(X_test)\n",
    "y_pred_proba = dt_clf.predict_proba(X_test)[:, 1] \n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(\"Decision Tree Accuracy:\", accuracy)\n",
    "print(\"Decision Tree ROC-AUC Score:\", roc_auc)\n",
    "print(\"\\nDecision Tree Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(5,3))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "            xticklabels=[0, 1], yticklabels=[0, 1])\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Decision Tree Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Plot the Decision Tree\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.set_cmap(\"YlGnBu\")\n",
    "tree.plot_tree(dt_clf, feature_names=X.columns, class_names=['No Housing Loan', 'Yes Housing Loan'], filled=True)\n",
    "plt.title(\"Decision Tree Visualization\")\n",
    "plt.show()\n",
    "\n",
    "predictions_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred,\n",
    "    'Predicted_Probability': y_pred_proba\n",
    "})\n",
    "\n",
    "# Save to a CSV file\n",
    "predictions_df.to_csv('housing_loan_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb6c789-4d56-43c5-a984-3110aea55080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC for Logistic Regression\n",
    "fpr_logreg, tpr_logreg, _ = roc_curve(y_test, logreg.predict_proba(X_test)[:, 1])\n",
    "roc_auc_logreg = roc_auc_score(y_test, logreg.predict_proba(X_test)[:, 1])\n",
    "\n",
    "# ROC for Decision Tree\n",
    "fpr_dt, tpr_dt, _ = roc_curve(y_test, dt_clf.predict_proba(X_test)[:, 1])\n",
    "roc_auc_dt = roc_auc_score(y_test, dt_clf.predict_proba(X_test)[:, 1])\n",
    "\n",
    "# Plotting both ROC curves\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr_logreg, tpr_logreg, label=f\"Logistic Regression (AUC = {roc_auc_logreg:.2f})\", color=\"blue\")\n",
    "plt.plot(fpr_dt, tpr_dt, label=f\"Decision Tree (AUC = {roc_auc_dt:.2f})\", color=\"green\")\n",
    "plt.plot([0, 1], [0, 1], 'k--')  \n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve Comparison: Logistic Regression vs Decision Tree\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
